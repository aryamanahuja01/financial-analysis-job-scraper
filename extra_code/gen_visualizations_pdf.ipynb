{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4be6d66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.58.0-cp312-cp312-macosx_10_13_universal2.whl.metadata (104 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.8-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from matplotlib) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.2.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.3-cp312-cp312-macosx_11_0_arm64.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp312-cp312-macosx_11_0_arm64.whl (255 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.0-cp312-cp312-macosx_10_13_universal2.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached kiwisolver-1.4.8-cp312-cp312-macosx_11_0_arm64.whl (65 kB)\n",
      "Downloading pillow-11.2.1-cp312-cp312-macosx_11_0_arm64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7/7\u001b[0m [matplotlib]7\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.0 kiwisolver-1.4.8 matplotlib-3.10.3 pillow-11.2.1 pyparsing-3.2.3\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from seaborn) (2.2.5)\n",
      "Requirement already satisfied: pandas>=1.2 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from seaborn) (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Requirement already satisfied: dotenv in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from dotenv) (1.1.0)\n",
      "Requirement already satisfied: sqlalchemy in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (2.0.40)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from sqlalchemy) (4.13.2)\n",
      "Requirement already satisfied: pandas in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kiperia/Documents/sample-code/arayaman-data-science/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install dotenv\n",
    "!pip install sqlalchemy\n",
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24684db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import pandas as pd\n",
    "\n",
    "# Load credentials from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Database connection info\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(\n",
    "    f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4816e046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/s4/h0k4q7kx7s52yzr_bd9cvj140000gn/T/ipykernel_19095/3852868311.py:10: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  sql_query = '''\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# ======================================================\n",
    "# ðŸ“Š Indeed Jobs - Descriptive Query\n",
    "# ======================================================\n",
    "\n",
    "# Business Question:\n",
    "# What are the most common job titles on Indeed and their average listed salaries?\n",
    "\n",
    "sql_query = '''\n",
    "WITH cleaned_salaries AS (\n",
    "    SELECT \n",
    "        job_title,\n",
    "        CAST(job_salary AS INTEGER) AS salary\n",
    "    FROM indeed_jobs\n",
    "    WHERE job_salary ~ '^\\d{5,6}$'\n",
    "),\n",
    "job_summary AS (\n",
    "    SELECT \n",
    "        job_title,\n",
    "        COUNT(*) AS job_count,\n",
    "        AVG(salary) AS avg_salary\n",
    "    FROM cleaned_salaries\n",
    "    GROUP BY job_title\n",
    ")\n",
    "SELECT \n",
    "    job_title,\n",
    "    job_count,\n",
    "    ROUND(avg_salary) AS avg_salary\n",
    "FROM job_summary\n",
    "ORDER BY job_count DESC\n",
    "LIMIT 10;\n",
    "'''\n",
    "\n",
    "indeed_jobs_summary_df = pd.read_sql(sql_query, con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7344807",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Insight:\n",
    "# Job titles with the highest frequency often have highly variable salary data.\n",
    "\n",
    "# Recommendation:\n",
    "# Normalize salary data further or target roles with consistent salary representation.\n",
    "\n",
    "# Prediction:\n",
    "# Job roles with frequent listings may face increasing competition and wage pressure.\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# ðŸ•µï¸ Indeed Jobs - Diagnostic Query\n",
    "# ======================================================\n",
    "\n",
    "# Business Question:\n",
    "# Which companies most frequently post for the top job titles on Indeed?\n",
    "\n",
    "sql_query = '''\n",
    "WITH parsed_companies AS (\n",
    "    SELECT \n",
    "        job_title,\n",
    "        SPLIT_PART(company_name_location, 'Remote', 1) AS company_name\n",
    "    FROM indeed_jobs\n",
    "),\n",
    "ranked_companies AS (\n",
    "    SELECT \n",
    "        job_title,\n",
    "        TRIM(company_name) AS company_name,\n",
    "        COUNT(*) AS count,\n",
    "        RANK() OVER (PARTITION BY job_title ORDER BY COUNT(*) DESC) AS rank\n",
    "    FROM parsed_companies\n",
    "    GROUP BY job_title, company_name\n",
    ")\n",
    "SELECT \n",
    "    job_title,\n",
    "    company_name,\n",
    "    count\n",
    "FROM ranked_companies\n",
    "WHERE rank = 1\n",
    "ORDER BY count DESC;\n",
    "'''\n",
    "\n",
    "indeed_top_companies_df = pd.read_sql(sql_query, con=engine)\n",
    "\n",
    "\n",
    "# Insight:\n",
    "# The most frequent job titles tend to be associated with specific companies repeatedly.\n",
    "\n",
    "# Recommendation:\n",
    "# Consider targeting these employers in job scraping or analysis to identify hiring trends.\n",
    "\n",
    "# Prediction:\n",
    "# These companies may reflect strong growth or high employee turnover in key roles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f887f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“˜ Remote Jobs + Indeed Jobs Analysis Notebook\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# ======================================================\n",
    "# ðŸ“Š Remote Jobs - Descriptive Query\n",
    "# ======================================================\n",
    "\n",
    "# Business Question:\n",
    "# What are the average salary ranges grouped by job level?\n",
    "\n",
    "sql_query = '''\n",
    "WITH salary_data AS (\n",
    "    SELECT \n",
    "        job_level,\n",
    "        annual_salary_min,\n",
    "        annual_salary_max\n",
    "    FROM remote_jobs\n",
    "    WHERE annual_salary_min IS NOT NULL AND annual_salary_max IS NOT NULL\n",
    ")\n",
    "SELECT \n",
    "    job_level,\n",
    "    COUNT(*) AS job_count,\n",
    "    ROUND(AVG(annual_salary_min)) AS avg_salary_min,\n",
    "    ROUND(AVG(annual_salary_max)) AS avg_salary_max\n",
    "FROM salary_data\n",
    "GROUP BY job_level\n",
    "ORDER BY avg_salary_max DESC;\n",
    "'''\n",
    "\n",
    "remote_salary_df = pd.read_sql(sql_query, con=engine)\n",
    "\n",
    "\n",
    "# Insight:\n",
    "# Senior level jobs tend to have a higher salary range on average.\n",
    "# Entry-level jobs offer significantly lower pay.\n",
    "\n",
    "# Recommendation:\n",
    "# Focus job scraping on higher-level positions to target premium salary ranges.\n",
    "\n",
    "# Prediction:\n",
    "# As remote work trends grow, mid-level roles may see upward salary adjustment.\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# ðŸ•µï¸ Remote Jobs - Diagnostic Query\n",
    "# ======================================================\n",
    "\n",
    "# Business Question:\n",
    "# Which companies are posting the most high-paying jobs?\n",
    "\n",
    "sql_query = '''\n",
    "WITH high_salary_jobs AS (\n",
    "    SELECT \n",
    "        company_name,\n",
    "        annual_salary_max,\n",
    "        ROW_NUMBER() OVER (PARTITION BY company_name ORDER BY annual_salary_max DESC) AS rank\n",
    "    FROM remote_jobs\n",
    "    WHERE annual_salary_max > 100000\n",
    ")\n",
    "SELECT \n",
    "    company_name,\n",
    "    COUNT(*) AS high_paying_jobs\n",
    "FROM high_salary_jobs\n",
    "WHERE rank <= 5\n",
    "GROUP BY company_name\n",
    "ORDER BY high_paying_jobs DESC;\n",
    "'''\n",
    "\n",
    "remote_highpay_df = pd.read_sql(sql_query, con=engine)\n",
    "\n",
    "\n",
    "# Insight:\n",
    "# Certain companies consistently post high-paying jobs above 100k.\n",
    "\n",
    "# Recommendation:\n",
    "# Consider building partnerships with those companies or tracking their listings.\n",
    "\n",
    "# Prediction:\n",
    "# Their hiring trends could be indicators of high growth sectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aaf0e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/h0k4q7kx7s52yzr_bd9cvj140000gn/T/ipykernel_19095/938394005.py:9: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(\n",
      "/var/folders/s4/h0k4q7kx7s52yzr_bd9cvj140000gn/T/ipykernel_19095/938394005.py:24: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(\n",
      "/var/folders/s4/h0k4q7kx7s52yzr_bd9cvj140000gn/T/ipykernel_19095/938394005.py:39: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a PDF file to store all figures\n",
    "with PdfPages(\"Visualizations.pdf\") as pdf:\n",
    "    # Plot 1: Remote Jobs - Salary by Level\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(\n",
    "        data=remote_salary_df,\n",
    "        x=\"avg_salary_max\",\n",
    "        y=\"job_level\",\n",
    "        palette=\"viridis\"\n",
    "    )\n",
    "    plt.title(\"Average Max Salary by Job Level (Remote Jobs)\")\n",
    "    plt.xlabel(\"Average Max Salary ($)\")\n",
    "    plt.ylabel(\"Job Level\")\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    # Plot 2: Remote Jobs - High Paying by Company\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(\n",
    "        data=remote_highpay_df.sort_values(\"high_paying_jobs\", ascending=False),\n",
    "        x=\"high_paying_jobs\",\n",
    "        y=\"company_name\",\n",
    "        palette=\"rocket\"\n",
    "    )\n",
    "    plt.title(\"High-Paying Job Postings by Company (>$100k)\")\n",
    "    plt.xlabel(\"Number of High-Paying Jobs\")\n",
    "    plt.ylabel(\"Company Name\")\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    # Plot 3: Indeed - Most Common Job Titles\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(\n",
    "        data=indeed_jobs_summary_df,\n",
    "        x=\"job_count\",\n",
    "        y=\"job_title\",\n",
    "        palette=\"coolwarm\"\n",
    "    )\n",
    "    plt.title(\"Top 10 Job Titles on Indeed\")\n",
    "    plt.xlabel(\"Job Count\")\n",
    "    plt.ylabel(\"Job Title\")\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    # Plot 4: Indeed - Top Companies by Job Title\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(\n",
    "        data=indeed_top_companies_df.sort_values(\"count\", ascending=False),\n",
    "        x=\"count\",\n",
    "        y=\"job_title\",\n",
    "        hue=\"company_name\",\n",
    "        dodge=False\n",
    "    )\n",
    "    plt.title(\"Top Companies for Most Common Job Titles\")\n",
    "    plt.xlabel(\"Job Post Count\")\n",
    "    plt.ylabel(\"Job Title\")\n",
    "    plt.legend(title=\"Company\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083fb0ba",
   "metadata": {},
   "source": [
    "## Explanation of how visualizations were created \n",
    "s\n",
    "The visualizations in the Visualizations.pdf file were created using Python by first querying the PostgreSQL database with pandas.read_sql() to create four dataframes based on descriptive and diagnostic analytics queries for both the remote_jobs and indeed_jobs datasets. Each dataframe was then visualized using matplotlib and seaborn to generate bar charts and other relevant plots that illustrate the insights and trends identified in the SQL queries. All visualizations were compiled into a single multi-page PDF file using matplotlib.backends.backend_pdf.PdfPages, resulting in a consolidated report that can be easily shared or reviewed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
